{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dbscan_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjdhc99uwvHl"
      },
      "source": [
        "!pip3 install vtk\n",
        "!pip3 install nipype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "YTk8pCSn-J9i",
        "outputId": "76c2ce32-c79f-4b0e-f73d-a80eb42aad78"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import vtk\n",
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nibabel as nib\n",
        "from pathlib import Path\n",
        "from sklearn import metrics\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from nipype.interfaces import fsl\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.cluster import DBSCAN\n",
        "from nipype.testing import example_data\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from google.colab import files  \n",
        "\n",
        "\n",
        "# defining nii to stl conversion\n",
        "\n",
        "def nii_2_mesh(filename_nii, filename_stl, label):\n",
        "\n",
        "    try:\n",
        "        \n",
        "        reader = vtk.vtkNIFTIImageReader()\n",
        "        reader.SetFileName(filename_nii)\n",
        "        reader.Update()\n",
        "        \n",
        "        surf = vtk.vtkDiscreteMarchingCubes()\n",
        "        surf.SetInputConnection(reader.GetOutputPort())\n",
        "        surf.SetValue(0, label)\n",
        "        surf.Update()\n",
        "        \n",
        "        smoother= vtk.vtkWindowedSincPolyDataFilter()\n",
        "        if vtk.VTK_MAJOR_VERSION <= 5:\n",
        "            smoother.SetInput(surf.GetOutput())\n",
        "        else:\n",
        "            smoother.SetInputConnection(surf.GetOutputPort())\n",
        "        smoother.SetNumberOfIterations(30)\n",
        "        smoother.NonManifoldSmoothingOn()\n",
        "        smoother.NormalizeCoordinatesOn()\n",
        "        smoother.GenerateErrorScalarsOn()\n",
        "        smoother.Update()\n",
        "         \n",
        "        writer = vtk.vtkSTLWriter()\n",
        "        writer.SetInputConnection(smoother.GetOutputPort())\n",
        "        writer.SetFileTypeToASCII()\n",
        "        writer.SetFileName(filename_stl)\n",
        "        writer.Write()\n",
        "        \n",
        "    except:\n",
        "        \n",
        "        pass\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    def working(X):\n",
        "\n",
        "        # Task 2 : DBSCAN Segmentation (C++ implementation)\n",
        "        cluster_label = str(X)[:2]\n",
        "\n",
        "        os.mkdir('Clusters_' + str(cluster_label))\n",
        "\n",
        "        print(\"\\nFor this DBSCAN segmentation, epsilon value is 25, and minpoints value is 40. For eps and minpts, edit main.cpp if needed. For size thresholds, edit this script.\")\n",
        "\n",
        "        a = nib.load(str(X))\n",
        "        A = np.array(a.dataobj)\n",
        "\n",
        "        valid_coord = []\n",
        "\n",
        "        for x in range(0,A.shape[0]-1):\n",
        "            for y in range(0,A.shape[1]-1):\n",
        "                for z in range(0,A.shape[2]-1):\n",
        "                    if (A[x][y][z] == 1):\n",
        "                        valid_coord += [[x,y,z]]\n",
        "\n",
        "        np.savetxt(\"valid_coord.csv\", valid_coord, delimiter=\",\")\n",
        "\n",
        "        with open('valid_coord.csv', newline='') as csvfile:\n",
        "            data = np.array(list(csv.reader(csvfile)))\n",
        "            data_float = data.astype(float)\n",
        "\n",
        "        add = np.array([[data_float.shape[0], ' ', ' ']])\n",
        "\n",
        "        DBSCAN_prep = np.concatenate((add, data_float))\n",
        "\n",
        "        np.savetxt(\"valid_coord.dat\", DBSCAN_prep, fmt='%s', delimiter=',')\n",
        "\n",
        "        os.remove(\"valid_coord.csv\")\n",
        "\n",
        "        df = pd.read_csv(\"valid_coord.dat\", sep=\";\", header=0)\n",
        "\n",
        "        df.rename(columns = lambda x: re.sub('\\D','',x),inplace=True)\n",
        "\n",
        "        df.to_csv(\"valid_coord_DBSCANprep.dat\", sep = ' ', index = False)\n",
        "\n",
        "        os.remove(\"valid_coord.dat\")\n",
        "\n",
        "        os.system(\"g++ main.cpp dbscan.cpp -o DBSCANcsv\")\n",
        "\n",
        "        os.system(\"./DBSCANcsv\")\n",
        "\n",
        "        os.remove(\"valid_coord_DBSCANprep.dat\")\n",
        "\n",
        "        # Cluster organization (cluster_label, Ashape, and valid_coord given from input)\n",
        "\n",
        "        DBSCANraw = np.genfromtxt('DBSCAN_raw.csv')\n",
        "\n",
        "        rownum = int(DBSCANraw.shape[0]/4 - 1)\n",
        "\n",
        "        cluster_max = 0\n",
        "\n",
        "        for i in range(rownum + 1):\n",
        "            if DBSCANraw[4*i + 3] >= cluster_max:\n",
        "                cluster_max = int(DBSCANraw[4*i + 3])\n",
        "            \n",
        "        cluster_lists = [[] for i in range(cluster_max + 1)]\n",
        "\n",
        "        for i in range(rownum + 1):\n",
        "            if DBSCANraw[4*i + 3] >= 1:\n",
        "                cluster_lists[int(DBSCANraw[4*i + 3])].append([valid_coord[i]])\n",
        "            \n",
        "        for r in range(1,cluster_max + 1):\n",
        "            cluster_indi = np.array(cluster_lists[r])\n",
        "            cluster_coord = np.zeros((A.shape[0], A.shape[1], A.shape[2]))\n",
        "            for s in range(len(cluster_indi)):\n",
        "                cluster_coord[cluster_indi[s][0][0],cluster_indi[s][0][1],cluster_indi[s][0][2]] = 1\n",
        "            if len(cluster_indi) >= 8000:\n",
        "                cluster_nib = nib.Nifti1Image(cluster_coord, affine=np.eye(4))\n",
        "                nib.save(cluster_nib, \"DBSCAN-cluster\" + str(r) + \".nii.gz\")\n",
        "                \n",
        "                filename_nii = \"DBSCAN-cluster\" + str(r) + \".nii.gz\"\n",
        "                filename_stl = filename_nii[:-7] + '.stl'\n",
        "                label = 1\n",
        "                \n",
        "                nii_2_mesh(filename_nii, filename_stl, label)\n",
        "                    \n",
        "                shutil.move(\"DBSCAN-cluster\" + str(r) + \".nii.gz\", 'Clusters_' + str(cluster_label))\n",
        "                shutil.move(\"DBSCAN-cluster\" + str(r) + \".stl\", 'Clusters_' + str(cluster_label))\n",
        "\n",
        "        os.remove(\"DBSCAN_raw.csv\")\n",
        "        shutil.move(str(X),'Clusters_' + str(cluster_label))\n",
        "\n",
        "        os.system(\"zip -r /content/Clusters_\" + str(cluster_label) + \".zip /content/Clusters_\" + str(cluster_label))\n",
        "        files.download(\"/content/Clusters_\" + str(cluster_label) + \".zip\")  \n",
        "\n",
        "#working('05_T1w_post_SCALP_normalized_filt_nonMNI_difference_post=0.nii.gz')\n",
        "#working('07_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "working('10_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "#working('13_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "#working('16_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "#working('20_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "#working('25_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "#working('26_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "#working('28_T1w_post_SCALP_normalized_filtered_nonMNI_difference_post=0.nii.gz')\n",
        "#working('28_T1w_post_SCALP_normalized_filtered_MNI_difference_post=0.nii.gz')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For this DBSCAN segmentation, epsilon value is 25, and minpoints value is 40. For eps and minpts, edit main.cpp if needed. For size thresholds, edit this script.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_463f8a33-1a5a-4679-8b42-ea7d64df3f85\", \"Clusters_10.zip\", 1991856)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2JHTmXTaUts"
      },
      "source": [
        "from google.colab import files  \n",
        "\n",
        "cluster_label = '28'\n",
        "\n",
        "os.system(\"zip -r /content/Clusters_\" + str(cluster_label) + \".zip /content/Clusters_\" + str(cluster_label))\n",
        "files.download(\"/content/Clusters_\" + str(cluster_label) + \".zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}